{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-76d58a13e791>:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for img_path in tqdm(os.listdir(\"Dataset/Flipkart/images\")):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44c124ebf5e4cad8dd96046b7c46eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        # Use VGG-16 as the architecture and ImageNet for the weight\n",
    "        base_model = VGG16(weights='imagenet')\n",
    "        # Customize the model to return features from fully-connected layer\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "    def extract(self, img):\n",
    "        # Resize the image\n",
    "        img = img.resize((224, 224))\n",
    "        # Convert the image color space\n",
    "        img = img.convert('RGB')\n",
    "        # Reformat the image\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Extract Features\n",
    "        feature = self.model.predict(x)[0]\n",
    "        return feature / np.linalg.norm(feature)\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "\n",
    "# Iterate through images (Change the path based on your image location)\n",
    "for img_path in tqdm(os.listdir(\"Dataset/Flipkart/images\")):\n",
    "    # Extract Features\n",
    "    feature = fe.extract(img=Image.open('Dataset/Flipkart/images/' + str(img_path)))\n",
    "    # Save the Numpy array (.npy) on designated path\n",
    "    feature_path = \"Dataset/Flipkart/features/{}.npy\".format(str(img_path).replace('.jpg',''))\n",
    "    np.save(feature_path, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
